{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Load data from json File\n",
    "2. Split data into train test split\n",
    "3. create neural net using using tensorflow and keras\n",
    "4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the python notebook state\n",
    "#dill.load_session('model_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    x = np.array(data['mfcc'])\n",
    "    y = np.array(data['labels'])\n",
    "    num_segments = data['num_segments']\n",
    "    mapping = data['mapping']\n",
    "    file_origin = data['file_origin']\n",
    "    \n",
    "    \n",
    "    return x, y, num_segments, mapping, file_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-3eb01ef62f97>\", line 1, in <module>\n",
      "    x, y, num_segments, mapping, file_origin = load_data(\"Data/data.json\")\n",
      "  File \"<ipython-input-7-6ae881e17355>\", line 3, in load_data\n",
      "    data = json.load(fp)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\json\\__init__.py\", line 293, in load\n",
      "    return loads(fp.read(),\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Albert\\anaconda3\\envs\\ML_env\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3eb01ef62f97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_origin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/data.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-6ae881e17355>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2045\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2047\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2048\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2050\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1437\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1337\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1194\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "x, y, num_segments, mapping, file_origin = load_data(\"Data/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "79940"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2, figsize = (15,15))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Create accuracy subplot\n",
    "    \n",
    "    axs[0].plot(history.history[\"acc\"], label = \"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_acc\"], label = \"test accuracy\")\n",
    "    axs[0].set_ylabel(\"accuracy\")\n",
    "    axs[0].legend(loc = \"lower right\")\n",
    "    axs[0].set_title(\"accuracy eval\")\n",
    "    \n",
    "    #Create Error subplot\n",
    "        \n",
    "    axs[1].plot(history.history[\"loss\"], label = \"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label = \"test error\")\n",
    "    axs[1].set_ylabel(\"error\")\n",
    "    axs[1].set_xlabel(\"epochs\")\n",
    "    axs[1].legend(loc = \"upper right\")\n",
    "    axs[1].set_title(\"error eval\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "    X = X[np.newaxis, :]\n",
    "    \n",
    "    # prediction = [[0.2, 0,2, ...]] probabilities\n",
    "    prediction = model.predict(X)\n",
    "    \n",
    "    #extrack index with max value (softmax gives you probabilities)\n",
    "    predicted_index = np.argmax(prediction, axis = 1)\n",
    "    \n",
    "    print(\"The prediction is: {}, The expected output is: {}\".format(mapping[int(predicted_index)], mapping[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create label encoder for inverse fit\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model Structure (Simple Dense Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0721 09:43:38.128442 139902445979456 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#this is going to be a basic neural network consisting of only dense layers\n",
    "model_1 = keras.Sequential([\n",
    "    #input layer\n",
    "    keras.layers.Flatten(input_shape = (x.shape[1], x.shape[2])),\n",
    "    \n",
    "    #1st hidden layer\n",
    "    keras.layers.Dense(512, activation = \"relu\"),\n",
    "    \n",
    "    #2nd hidden layers\n",
    "    keras.layers.Dense(256, activation = \"relu\"),\n",
    "    \n",
    "    #3rd hidden layers\n",
    "    keras.layers.Dense(64, activation = \"relu\"),\n",
    "    \n",
    "    keras.layers.Dense(len(mapping), activation = \"softmax\")\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1677)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               859136    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 1,007,432\n",
      "Trainable params: 1,007,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model_1.compile(optimizer = optimizer, loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59955 samples, validate on 19985 samples\n",
      "Epoch 1/50\n",
      "59955/59955 [==============================] - 4s 65us/sample - loss: 5.6765 - acc: 0.2495 - val_loss: 3.1523 - val_acc: 0.2634\n",
      "Epoch 2/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 2.6388 - acc: 0.2969 - val_loss: 2.4697 - val_acc: 0.2838\n",
      "Epoch 3/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 2.1496 - acc: 0.3295 - val_loss: 2.1661 - val_acc: 0.3316\n",
      "Epoch 4/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 1.9212 - acc: 0.3599 - val_loss: 2.0138 - val_acc: 0.3389\n",
      "Epoch 5/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 1.7906 - acc: 0.3880 - val_loss: 1.9850 - val_acc: 0.3439\n",
      "Epoch 6/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 1.6863 - acc: 0.4136 - val_loss: 2.0439 - val_acc: 0.3467\n",
      "Epoch 7/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 1.6157 - acc: 0.4326 - val_loss: 1.9353 - val_acc: 0.3601\n",
      "Epoch 8/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 1.5407 - acc: 0.4526 - val_loss: 1.8705 - val_acc: 0.3689\n",
      "Epoch 9/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 1.4792 - acc: 0.4736 - val_loss: 1.8935 - val_acc: 0.3653\n",
      "Epoch 10/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 1.4344 - acc: 0.4904 - val_loss: 1.9764 - val_acc: 0.3553\n",
      "Epoch 11/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 1.3834 - acc: 0.5072 - val_loss: 1.8754 - val_acc: 0.3788\n",
      "Epoch 12/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 1.3384 - acc: 0.5270 - val_loss: 1.8409 - val_acc: 0.3897\n",
      "Epoch 13/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 1.2842 - acc: 0.5437 - val_loss: 1.8777 - val_acc: 0.3857\n",
      "Epoch 14/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 1.2392 - acc: 0.5598 - val_loss: 1.9611 - val_acc: 0.3805\n",
      "Epoch 15/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 1.2091 - acc: 0.5721 - val_loss: 1.9077 - val_acc: 0.3833\n",
      "Epoch 16/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 1.1525 - acc: 0.5937 - val_loss: 1.9438 - val_acc: 0.3946\n",
      "Epoch 17/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 1.1147 - acc: 0.6079 - val_loss: 1.9271 - val_acc: 0.3987\n",
      "Epoch 18/50\n",
      "59955/59955 [==============================] - 4s 64us/sample - loss: 1.0696 - acc: 0.6253 - val_loss: 1.9310 - val_acc: 0.3967\n",
      "Epoch 19/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 1.0391 - acc: 0.6346 - val_loss: 2.0432 - val_acc: 0.3994\n",
      "Epoch 20/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.9985 - acc: 0.6482 - val_loss: 2.0076 - val_acc: 0.3998\n",
      "Epoch 21/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.9658 - acc: 0.6604 - val_loss: 2.0506 - val_acc: 0.3989\n",
      "Epoch 22/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.9289 - acc: 0.6749 - val_loss: 2.0601 - val_acc: 0.4023\n",
      "Epoch 23/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.8993 - acc: 0.6857 - val_loss: 2.1457 - val_acc: 0.3882\n",
      "Epoch 24/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.8596 - acc: 0.7026 - val_loss: 2.1750 - val_acc: 0.3939\n",
      "Epoch 25/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 0.8332 - acc: 0.7114 - val_loss: 2.1942 - val_acc: 0.3995\n",
      "Epoch 26/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.8020 - acc: 0.7230 - val_loss: 2.2487 - val_acc: 0.4029\n",
      "Epoch 27/50\n",
      "59955/59955 [==============================] - 4s 59us/sample - loss: 0.7713 - acc: 0.7338 - val_loss: 2.3139 - val_acc: 0.3963\n",
      "Epoch 28/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.7495 - acc: 0.7419 - val_loss: 2.3134 - val_acc: 0.4003\n",
      "Epoch 29/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 0.7149 - acc: 0.7545 - val_loss: 2.3989 - val_acc: 0.4082\n",
      "Epoch 30/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.6845 - acc: 0.7647 - val_loss: 2.4054 - val_acc: 0.4080\n",
      "Epoch 31/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.6711 - acc: 0.7720 - val_loss: 2.4656 - val_acc: 0.4116\n",
      "Epoch 32/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.6417 - acc: 0.7794 - val_loss: 2.5111 - val_acc: 0.4120\n",
      "Epoch 33/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.6224 - acc: 0.7878 - val_loss: 2.5214 - val_acc: 0.4047\n",
      "Epoch 34/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.5920 - acc: 0.7975 - val_loss: 2.6135 - val_acc: 0.4133\n",
      "Epoch 35/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.5772 - acc: 0.8028 - val_loss: 2.7385 - val_acc: 0.3907\n",
      "Epoch 36/50\n",
      "59955/59955 [==============================] - 4s 63us/sample - loss: 0.5559 - acc: 0.8118 - val_loss: 2.7344 - val_acc: 0.4071\n",
      "Epoch 37/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 0.5311 - acc: 0.8211 - val_loss: 2.7855 - val_acc: 0.3998\n",
      "Epoch 38/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.5163 - acc: 0.8254 - val_loss: 2.8999 - val_acc: 0.4038\n",
      "Epoch 39/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.4967 - acc: 0.8336 - val_loss: 2.9342 - val_acc: 0.4039\n",
      "Epoch 40/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 0.4876 - acc: 0.8350 - val_loss: 3.0184 - val_acc: 0.3954\n",
      "Epoch 41/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.4662 - acc: 0.8441 - val_loss: 3.0242 - val_acc: 0.4023\n",
      "Epoch 42/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.4498 - acc: 0.8492 - val_loss: 3.0921 - val_acc: 0.3953\n",
      "Epoch 43/50\n",
      "59955/59955 [==============================] - 4s 63us/sample - loss: 0.4536 - acc: 0.8477 - val_loss: 3.0954 - val_acc: 0.4045\n",
      "Epoch 44/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.4337 - acc: 0.8554 - val_loss: 3.1841 - val_acc: 0.4025\n",
      "Epoch 45/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.4032 - acc: 0.8662 - val_loss: 3.2819 - val_acc: 0.4045\n",
      "Epoch 46/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.3939 - acc: 0.8695 - val_loss: 3.3477 - val_acc: 0.4037\n",
      "Epoch 47/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.3938 - acc: 0.8682 - val_loss: 3.4173 - val_acc: 0.4042\n",
      "Epoch 48/50\n",
      "59955/59955 [==============================] - 4s 61us/sample - loss: 0.3773 - acc: 0.8764 - val_loss: 3.4263 - val_acc: 0.4077\n",
      "Epoch 49/50\n",
      "59955/59955 [==============================] - 4s 60us/sample - loss: 0.3564 - acc: 0.8819 - val_loss: 3.4728 - val_acc: 0.3984\n",
      "Epoch 50/50\n",
      "59955/59955 [==============================] - 4s 62us/sample - loss: 0.3422 - acc: 0.8880 - val_loss: 3.5928 - val_acc: 0.4125\n"
     ]
    }
   ],
   "source": [
    "#this model overfits greatly\n",
    "history_1 = model_1.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-51706ed26e9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'2.3.0'"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(tf.__version__)\n",
    "import sys\n",
    "display(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model Structure (Convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a657ff63d526>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_test_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train_cnn = np.expand_dims(x_train, axis = -1)\n",
    "x_test_cnn = np.expand_dims(x_test, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_train_cnn' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1595d2390d56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "x_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_train_cnn' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5c142f9d2cc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model_cnn = keras.Sequential([\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#1st convlayer (input)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#Downsizing MaxPool layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape = x_train_cnn.shape[1:]\n",
    "model_cnn = keras.Sequential([\n",
    "    #1st convlayer (input)\n",
    "    keras.layers.Conv2D(32, (3,3), strides=1,padding = 'same',input_shape = input_shape, activation = 'relu'),\n",
    "    #Downsizing MaxPool layer\n",
    "    keras.layers.Conv2D(32, (3,3), strides=1,padding = 'same',activation = 'relu'),\n",
    "    keras.layers.MaxPool2D((3,3), strides = (2,2), padding = 'same'),\n",
    "    #normalizes activation\n",
    "    keras.layers.BatchNormalization(),\n",
    "                        \n",
    "    #2nd conv layer\n",
    "    keras.layers.Conv2D(64, (3,3),strides=1,padding = 'same', activation = 'relu'),\n",
    "    keras.layers.Conv2D(64, (3,3), strides=1,padding = 'same',activation = 'relu'),\n",
    "    keras.layers.MaxPool2D((3,3), strides = (2,2), padding = 'same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(128, (3,3),strides=1,padding = 'same', activation = 'relu'),\n",
    "    keras.layers.Conv2D(128, (3,3), strides=1,padding = 'same',activation = 'relu'),\n",
    "    keras.layers.MaxPool2D((3,3), strides = (2,2), padding = 'same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "    keras.layers.Dropout(0.3),                    \n",
    "    #flatten the output to feed to dense output layer\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "                    \n",
    "    #Dense output layer\n",
    "    keras.layers.Dense(len(mapping), activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model_cnn' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8f148f6493c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model_cnn.compile(optimizer = optimizer, loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model_cnn' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3cd33cdc549e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "history_cnn = model_cnn.fit(x_train_cnn, y_train, validation_data = (x_test_cnn, y_test), batch_size = 128, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-221b11e75762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_cnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homework\n",
    "#Presentation\n",
    "#Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction is: Instrumental, The expected output is: Instrumental\n"
     ]
    }
   ],
   "source": [
    "test_case = 106\n",
    "x = x_test_cnn[test_case]\n",
    "y = y_test[test_case]\n",
    "predict(model_cnn, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79940, 129, 13)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_y = model_cnn.predict(np.expand_dims(x, axis = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(prediction_y, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb5183b7c50>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x.shape[1:]\n",
    "model_lstm = keras.Sequential()\n",
    "\n",
    "#2 lstm layers\n",
    "model_lstm.add(keras.layers.LSTM(64, input_shape = input_shape, return_sequences = True))\n",
    "model_lstm.add(keras.layers.LSTM(64))\n",
    "\n",
    "#dense layer\n",
    "model_lstm.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "\n",
    "#dropout layer\n",
    "model_lstm.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "#output layer\n",
    "model_lstm.add(keras.layers.Dense(len(mapping), activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 129, 64)           19968     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 57,672\n",
      "Trainable params: 57,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model_lstm.compile(optimizer = optimizer, loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 10:53:05.313315 139902445979456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59955 samples, validate on 19985 samples\n",
      "Epoch 1/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.9550 - acc: 0.2452 - val_loss: 1.8089 - val_acc: 0.3297\n",
      "Epoch 2/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.7964 - acc: 0.3269 - val_loss: 1.7372 - val_acc: 0.3569\n",
      "Epoch 3/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.7436 - acc: 0.3527 - val_loss: 1.6987 - val_acc: 0.3732\n",
      "Epoch 4/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.7057 - acc: 0.3725 - val_loss: 1.6730 - val_acc: 0.3860\n",
      "Epoch 5/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.6771 - acc: 0.3870 - val_loss: 1.6514 - val_acc: 0.3933\n",
      "Epoch 6/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.6560 - acc: 0.3960 - val_loss: 1.6339 - val_acc: 0.4010\n",
      "Epoch 7/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.6346 - acc: 0.4073 - val_loss: 1.6216 - val_acc: 0.4097\n",
      "Epoch 8/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.6189 - acc: 0.4138 - val_loss: 1.6131 - val_acc: 0.4130\n",
      "Epoch 9/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.6013 - acc: 0.4222 - val_loss: 1.6006 - val_acc: 0.4190\n",
      "Epoch 10/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5899 - acc: 0.4276 - val_loss: 1.5877 - val_acc: 0.4247\n",
      "Epoch 11/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5761 - acc: 0.4351 - val_loss: 1.5817 - val_acc: 0.4233\n",
      "Epoch 12/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5613 - acc: 0.4400 - val_loss: 1.5747 - val_acc: 0.4288\n",
      "Epoch 13/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5521 - acc: 0.4458 - val_loss: 1.5641 - val_acc: 0.4343\n",
      "Epoch 14/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5420 - acc: 0.4496 - val_loss: 1.5562 - val_acc: 0.4377\n",
      "Epoch 15/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5307 - acc: 0.4557 - val_loss: 1.5468 - val_acc: 0.4431\n",
      "Epoch 16/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.5232 - acc: 0.4589 - val_loss: 1.5439 - val_acc: 0.4434\n",
      "Epoch 17/30\n",
      "59955/59955 [==============================] - 131s 2ms/sample - loss: 1.5145 - acc: 0.4623 - val_loss: 1.5391 - val_acc: 0.4431\n",
      "Epoch 18/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.5039 - acc: 0.4644 - val_loss: 1.5349 - val_acc: 0.4482\n",
      "Epoch 19/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4953 - acc: 0.4685 - val_loss: 1.5297 - val_acc: 0.4490\n",
      "Epoch 20/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4898 - acc: 0.4709 - val_loss: 1.5273 - val_acc: 0.4499\n",
      "Epoch 21/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4792 - acc: 0.4748 - val_loss: 1.5223 - val_acc: 0.4524\n",
      "Epoch 22/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4750 - acc: 0.4777 - val_loss: 1.5203 - val_acc: 0.4524\n",
      "Epoch 23/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4665 - acc: 0.4808 - val_loss: 1.5213 - val_acc: 0.4517\n",
      "Epoch 24/30\n",
      "59955/59955 [==============================] - 133s 2ms/sample - loss: 1.4593 - acc: 0.4817 - val_loss: 1.5086 - val_acc: 0.4551\n",
      "Epoch 25/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.4524 - acc: 0.4874 - val_loss: 1.5059 - val_acc: 0.4576\n",
      "Epoch 26/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4482 - acc: 0.4884 - val_loss: 1.5027 - val_acc: 0.4608\n",
      "Epoch 27/30\n",
      "59955/59955 [==============================] - 128s 2ms/sample - loss: 1.4426 - acc: 0.4897 - val_loss: 1.5004 - val_acc: 0.4591\n",
      "Epoch 28/30\n",
      "59955/59955 [==============================] - 129s 2ms/sample - loss: 1.4353 - acc: 0.4910 - val_loss: 1.4972 - val_acc: 0.4634\n",
      "Epoch 29/30\n",
      "59955/59955 [==============================] - 129s 2ms/sample - loss: 1.4308 - acc: 0.4924 - val_loss: 1.4966 - val_acc: 0.4608\n",
      "Epoch 30/30\n",
      "59955/59955 [==============================] - 130s 2ms/sample - loss: 1.4219 - acc: 0.4965 - val_loss: 1.4925 - val_acc: 0.4646\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model_lstm.fit(x_train, y_train, validation_data = (x_test, y_test), batch_size = 128, epochs = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cbd7044962ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_lstm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train_cnn.shape[1:]\n",
    "model_cnn_lstm = keras.Sequential()\n",
    "\n",
    "#CNN Model\n",
    "model_cnn_lstm.add(TimeDistributed(keras.layers.Conv2D(32, (3,3), strides=1,padding = 'same', input_shape = input_shape, activation = 'relu')))\n",
    "model_cnn_lstm.add(TimeDistributed(keras.layers.Conv2D(32, (3,3), strides=1,padding = 'same',activation = 'relu')))\n",
    "model_cnn_lstm.add(TimeDistributed(keras.layers.MaxPool2D((3,3), strides = (2,2), padding = 'same')))\n",
    "# model_cnn_lstm.add(TimeDistributed(keras.layers.Flatten()))\n",
    "                   \n",
    "#LSTM Model\n",
    "model_cnn_lstm.add(keras.layers.LSTM(64, activation = 'relu'))\n",
    "model_cnn_lstm.add(keras.layers.LSTM(64, activation = 'relu'))  \n",
    "#dense layer\n",
    "model_cnn_lstm.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "\n",
    "#dropout layer\n",
    "model_cnn_lstm.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "#output layer\n",
    "model_cnn_lstm.add(keras.layers.Dense(len(mapping), activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d31429a340ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_cnn_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_cnn_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1451\u001b[0m     \"\"\"\n\u001b[1;32m   1452\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1454\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model_cnn_lstm.compile(optimizer = optimizer, loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model_cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input tensor must have rank 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    927\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    982\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" %\n\u001b[0;32m--> 983\u001b[0;31m                          (self, other))\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 13, 1) and (?, ?, ?, ?) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    933\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 13, 1) and (?, ?, ?, ?) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m       \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_spatial_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (?, 13, 1) must have rank 4",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b48aa41d3ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_cnn_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2416\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2619\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2621\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2622\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2706\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mchild_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_padding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         data_format=conv_utils.convert_data_format(self.data_format,\n\u001b[0;32m--> 193\u001b[0;31m                                                    self.rank + 2))\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       raise ValueError(\n\u001b[0;32m-> 1067\u001b[0;31m           \"input tensor must have rank %d\" % (num_spatial_dims + 2))\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: input tensor must have rank 4"
     ]
    }
   ],
   "source": [
    "history_cnn_lstm = model_cnn_lstm.fit(x_train_cnn, y_train, validation_data = (x_test_cnn, y_test), batch_size = 128, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70f3d42b2fb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_lstm_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_lstm.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lstm_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_lstm' is not defined"
     ]
    }
   ],
   "source": [
    "#Save notebook state\n",
    "dill.dump_session('model_env.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ML_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5a677ea0bef2c636820ad1981ea5624125874b378886a403aa26eeafdc3cf024"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}